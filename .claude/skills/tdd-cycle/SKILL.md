---
name: tdd-cycle
description: TDD（テスト駆動開発）のワークフローです。Red-Review-Green-Refactorサイクルを実行し、テストの「質」も担保するテストファースト開発を支援します。ユーザーが「TDDで開発して」「テスト駆動で実装して」「/tdd」と言ったときに使用します。
---

# TDD Cycle Workflow

## Overview

TDD (Test-Driven Development) の4ステップを**厳密に順序通り**実行します。
各フェーズをスキップせず、必ず順番に完了させてください。

> **Note**: REVIEWフェーズはテストの「質」を担保するために追加されました。
> Progressive Patternにより、1観点ずつ集中して評価することで高精度なレビューを実現します。

## The TDD Mantra

```
📋 PLAN   → テストを計画する（網羅性を確保）
🔴 RED    → テストを書く（失敗する）
🔍 REVIEW → テスト項目の妥当性を評価（80点以上で次へ）
🟢 GREEN  → 最小限のコードで通す
🔵 REFACTOR → コードを改善する
```

---

## Phase 0: 📋 ファイル判定 - テスト要否の確認

**目的**: 変更ファイルを確認し、TDDサイクルと動作確認モードのどちらを適用するか判定する

### 手順

1. **変更ファイルの一覧を取得**
   ```bash
   git status --short
   ```

2. **判定ロジック**

   `.claude/rules/testing.md` の「テスト要否の判断基準」テーブルに基づき判定する：

   | ファイルパターン | テスト要否 | 理由 |
   |----------------|-----------|------|
   | `*.py`, `*.js`, `*.ts`, `*.jsx`, `*.tsx` | 必須 | コードロジック変更 |
   | `.github/workflows/*.yml` | 必須 | CI/CD設定は動作確認必要 |
   | `pyproject.toml` | 必須 | 依存関係変更の影響確認 |
   | `*.md`, `*.json`, `*.yaml` | 不要 | ドキュメント/設定ファイル |
   | `.claude/**/*.md` | 不要 | ワークフロー定義 |

3. **判定結果**

   | 条件 | 適用モード |
   |------|-----------|
   | テスト必須ファイルが1つでも含まれる | → 通常TDDサイクル（Phase 1: PLANへ） |
   | テスト不要ファイルのみ | → 動作確認モード（下記参照） |

### 出力形式

```markdown
## 📋 Phase 0: ファイル判定完了

**変更ファイル**:
- {ファイル1} → {テスト必須/不要}
- {ファイル2} → {テスト必須/不要}

**判定**: {通常TDDサイクル / 動作確認モード}

→ {Phase 1: PLAN へ進みます / 動作確認モードを開始します}
```

---

## 動作確認モード（テスト不要ファイル向け）

Phase 0 で「テスト不要ファイルのみ」と判定された場合、TDDサイクルの代わりにこのモードを実行します。

### Step 1: チェックリストの特定

変更ファイルのタイプに応じて、`.claude/rules/testing.md` の「動作確認（テスト不要ファイル向け）」セクションから該当するチェック項目を抽出します。

### Step 2: 動作確認の実施

抽出したチェック項目を1つずつ確認します。確認方法は以下のいずれか：

- **目視確認**: ファイル内容を読み取り、基準を満たしているか確認
- **コマンド実行**: 構文チェック等が可能な場合は実行
- **整合性確認**: 関連ファイルとの整合性を確認

### Step 3: 結果の記録

確認完了後、Issueコメントに結果を投稿します：

```bash
# 環境に応じた日時取得（クロスプラットフォーム対応）
CONFIRM_DATE=$(date "+%Y-%m-%d %H:%M:%S" 2>/dev/null || powershell -Command "Get-Date -Format 'yyyy-MM-dd HH:mm:ss'")

# 使用モデル情報（TDD REVIEWのデフォルトモデル: Haiku）
EXECUTOR="Claude Code直接実行"
MODEL="Haiku"

gh issue comment {issue番号} --body "$(cat <<EOF
## 動作確認結果 - ${CONFIRM_DATE}

### 実行情報
- **実行者**: ${EXECUTOR}
- **使用モデル**: ${MODEL}
- **実行日時**: ${CONFIRM_DATE}

### 変更ファイル
- {ファイル1}
- {ファイル2}

### チェック結果
- [x] {確認項目1}
- [x] {確認項目2}
- [x] {確認項目3}

### 確認方法
- {どのように確認したか}

### 判定: ✅ 確認完了
EOF
)"
```

### 完了条件

- [ ] すべてのチェック項目が確認済み
- [ ] 結果がIssueコメントに投稿済み

### 出力形式

```markdown
## 📋 動作確認モード完了

**変更ファイル**: {ファイルリスト}
**チェック項目数**: {N}項目
**結果**: ✅ すべて確認完了

→ /review へ進みます
```

---

## Phase 1: 📋 PLAN - テスト計画

**目的**: テスト作成前に必要なテストケースを計画し、網羅性を確保する

### なぜPLANフェーズが必要か

- テスト作成前に「何をテストすべきか」を明確化
- テストケースの網羅性が個人の経験に依存することを防ぐ
- REVIEWフェーズでの手戻りを最小化
- REVIEWフェーズの評価基準に沿って事前に計画することで、テストの質を向上

### 手順

1. **受け入れ基準の確認**
   - Issueの受け入れ基準を確認
   - 実装する機能の仕様を明確にする

2. **テストケースの洗い出し**

   以下の観点でテストケースを計画（REVIEWフェーズの評価観点に対応）：

   #### 正常系（REVIEW Step 1に対応）
   - [ ] 基本的な成功パスのテスト
   - [ ] 主要なユースケースのテスト

   #### 異常系（REVIEW Step 2に対応）
   - [ ] エラー入力のテスト
   - [ ] 例外ハンドリングのテスト
   - [ ] 無効な状態のテスト

   #### 境界値（REVIEW Step 3に対応）
   - [ ] 最小値/最大値のテスト
   - [ ] 空/null/undefinedのテスト
   - [ ] 境界条件のテスト

   #### 受け入れ基準対応（REVIEW Step 4に対応）
   - [ ] 各受け入れ基準に対応するテスト

3. **テスト設計方針の決定（REVIEW Step 5に対応）**
   - モック/スタブの使用方針
   - テストデータの準備方法
   - テストの独立性をどう確保するか

### 完了条件

- [ ] テストケースが正常系・異常系・境界値の観点で洗い出されている
- [ ] 受け入れ基準に対応するテストが計画されている
- [ ] テスト設計方針が明確になっている

### 出力形式

テスト計画を以下の形式で出力：

```markdown
## 📋 PLAN Phase 完了

**テスト対象**: {機能名}

**正常系テストケース**:
- `test_xxx`: {テストの意図}
- `test_yyy`: {テストの意図}

**異常系テストケース**:
- `test_error_xxx`: {テストの意図}

**境界値テストケース**:
- `test_boundary_xxx`: {テストの意図}

**受け入れ基準対応**:
- 基準1: `test_xxx`, `test_yyy`
- 基準2: `test_zzz`

**テスト設計方針**:
- {モック/スタブの方針}
- {テストデータの方針}

→ RED Phase へ進みます
```

---

## Phase 2: 🔴 RED - テストを書く

**目的**: PLANフェーズで計画したテストケースを実装する

### 手順

1. **計画の確認**
   - PLANフェーズで作成した計画を参照
   - 実装するテストの優先順位を確認

2. **テストコードの作成**
   ```
   - テストファイルを作成（例: test_機能名.py）
   - 計画したテストケースを実装
   - 意図が明確な命名を使用
   ```

3. **テストの実行（失敗を確認）**
   ```bash
   # Python
   pytest test_機能名.py -v

   # JavaScript
   npm test
   ```

### 完了条件

- [ ] テストが**失敗する**ことを確認
- [ ] 失敗理由が「実装がない」であること（構文エラーではない）
- [ ] PLANフェーズで計画したテストケースが実装されている

### 出力形式

```markdown
## 🔴 RED Phase 完了

**作成したテスト**: {ファイルパス}

**テストケース**:
- `test_xxx`: {テストの意図}
- `test_yyy`: {テストの意図}

**実行結果**: ❌ FAILED (expected)
- {失敗したテスト数} / {全テスト数} 失敗

→ REVIEW Phase へ進みます
```

---

## Phase 3: 🔍 REVIEW - テスト項目の妥当性評価

**目的**: 作成したテストが十分な品質を持っているかを評価する

### 実行方式: Codex委任

このフェーズでは `codex-delegate` スキルを使用してCodex CLIにレビューを委任します。

```
codex-delegateスキルを使用して、tdd-reviewを実行してください。
対象: {テストファイルパス}
Issue: #{issue番号}
```

Codex CLIが利用できない場合は、以下の手順で従来通りメインエージェント内で実行してください。

### なぜREVIEWフェーズが必要か

- テストの「量」（カバレッジ）だけでなく「質」を担保する
- Progressive Pattern により、1観点ずつ集中して評価することで精度向上
- 不十分なテストのまま実装に進むことを防ぐ

### 評価方法: Progressive Pattern（5ステップ）

⚠️ **重要**: 各ステップは**1つの観点だけに集中**して評価してください。複数の観点を同時に評価すると精度が落ちます。

#### Step 1: 正常系チェック（20点）

この観点だけに集中して評価してください：

- [ ] 基本的な成功パスのテストがあるか
- [ ] 主要なユースケースがカバーされているか
- [ ] 期待される出力が明確に検証されているか

**スコア**: ___/20点

#### Step 2: 異常系チェック（20点）

この観点だけに集中して評価してください：

- [ ] エラー入力に対するテストがあるか
- [ ] 例外・エラーハンドリングのテストがあるか
- [ ] 無効な状態に対するテストがあるか

**スコア**: ___/20点

#### Step 3: 境界値チェック（20点）

この観点だけに集中して評価してください：

- [ ] 最小値/最大値のテストがあるか
- [ ] 空/null/undefinedのテストがあるか
- [ ] 境界条件（0, 1, N-1, N, N+1等）のテストがあるか

**スコア**: ___/20点

#### Step 4: 要件対応チェック（20点）

この観点だけに集中して評価してください：

- [ ] ビジネス要件・受け入れ基準との対応が明確か
- [ ] Issue/仕様に記載された条件がテストされているか
- [ ] テストケース名から意図が読み取れるか

**スコア**: ___/20点

#### Step 5: 品質特性チェック（20点）

この観点だけに集中して評価してください：

- [ ] テストがリファクタリングに耐えられるか（実装詳細に依存していないか）
- [ ] テストの保守性は高いか（AAAパターン、適切な命名）
- [ ] テストの意図が明確で、失敗時に原因がわかりやすいか

**スコア**: ___/20点

### 判定基準（80点ルール）

| 総合スコア | 判定 | アクション |
|-----------|------|-----------|
| **80点以上** | ✅ PASS | GREEN Phase へ進む |
| **60-79点** | ⚠️ 要改善 | 不足しているテストを追加し、再評価 |
| **60点未満** | ❌ 要見直し | テスト設計を根本から見直す |

### 完了条件

- [ ] 5ステップすべての評価が完了
- [ ] 総合スコアが**80点以上**

### 出力形式

```markdown
## 🔍 REVIEW Phase 完了

**評価結果**:

| Step | 観点 | スコア | 状態 |
|------|------|--------|------|
| 1 | 正常系 | __/20 | ✅/⚠️/❌ |
| 2 | 異常系 | __/20 | ✅/⚠️/❌ |
| 3 | 境界値 | __/20 | ✅/⚠️/❌ |
| 4 | 要件対応 | __/20 | ✅/⚠️/❌ |
| 5 | 品質特性 | __/20 | ✅/⚠️/❌ |

**総合スコア**: __/100点

**判定**: ✅ PASS / ⚠️ 要改善 / ❌ 要見直し

**改善が必要な場合**:
- {追加すべきテストケース}
- {修正すべき点}

→ GREEN Phase へ進みます
```

---

## Phase 4: 🟢 GREEN - テストを通す

**目的**: テストを通す**最小限の**コードを書く

### 重要なルール

⚠️ **このフェーズでやること**:
- テストを通すことだけに集中
- 最小限のコードを書く
- 動くコードを書く

⚠️ **このフェーズでやらないこと**:
- コードの美しさを追求しない
- 将来の拡張を考えない
- リファクタリングしない

### 手順

1. **最小限の実装**
   - テストが通る最もシンプルなコードを書く
   - ハードコードでも構わない（後でリファクタリング）

2. **テストの実行（成功を確認）**
   ```bash
   # Python
   pytest test_機能名.py -v

   # JavaScript
   npm test
   ```

### 完了条件

- [ ] すべてのテストが**成功する**こと
- [ ] 新規のテスト失敗がないこと

### 出力形式

```markdown
## 🟢 GREEN Phase 完了

**実装したファイル**: {ファイルパス}

**実行結果**: ✅ PASSED
- {成功したテスト数} / {全テスト数} 成功

**実装の概要**:
- {何を実装したか}

→ REFACTOR Phase へ進みます
```

---

## Phase 5: 🔵 REFACTOR - コードを改善する

**目的**: テストを壊さずにコードを改善する

### 重要なルール

⚠️ **このフェーズでやること**:
- コードの重複を排除
- 命名を改善
- 構造を整理
- 可読性を向上

⚠️ **このフェーズでやらないこと**:
- 新機能を追加しない
- テストを変更しない（リファクタリングのためのテスト追加は可）

### チェックリスト

- [ ] 重複コードはないか
- [ ] 命名は適切か
- [ ] 関数は単一責任か
- [ ] コメントは必要最小限か
- [ ] テストは依然として通るか

### 手順

1. **コードの改善**
   - 1つずつ小さな改善を行う
   - 改善のたびにテストを実行

2. **テストの実行（成功を維持）**
   ```bash
   pytest test_機能名.py -v
   ```

### 完了条件

- [ ] リファクタリング完了
- [ ] すべてのテストが**成功する**こと

### 出力形式

```markdown
## 🔵 REFACTOR Phase 完了

**改善内容**:
- {改善1}
- {改善2}

**実行結果**: ✅ PASSED
- {成功したテスト数} / {全テスト数} 成功

---

## 🎉 TDD Cycle 完了

**サマリー**:
- テストケース数: {N}
- カバレッジ: {X}% (目標: 80%以上)
- 実装ファイル: {ファイルリスト}

**次のアクション**:
- [ ] 次の機能のTDDサイクルを開始
- [ ] または、実装完了
```

---

## Cycle Continuation

1つの機能が完了したら：

1. **追加機能がある場合** → Phase 1 (PLAN) に戻る
2. **完了の場合** → 最終サマリーを出力

```markdown
## TDD Session 完了

**実装した機能**:
1. {機能1}
2. {機能2}

**総テストケース数**: {N}
**最終カバレッジ**: {X}%

**作成されたファイル**:
- {ファイル1}
- {ファイル2}
```

---

## Usage Example

```
User: ユーザー認証機能をTDDで実装して

Agent:
🔴 [RED] テストを書きます...
   - test_user_login_with_valid_credentials
   - test_user_login_with_invalid_password
   → テスト失敗を確認 ✓

🔍 [REVIEW] テスト項目を評価します...
   - Step 1: 正常系 → 18/20点
   - Step 2: 異常系 → 16/20点
   - Step 3: 境界値 → 14/20点 → 空文字テスト追加
   - Step 4: 要件対応 → 18/20点
   - Step 5: 品質特性 → 16/20点
   → 総合: 82/100点 ✅ PASS

🟢 [GREEN] 最小限の実装をします...
   - login関数を実装
   → テスト成功を確認 ✓

🔵 [REFACTOR] コードを改善します...
   - パスワードハッシュ化を関数に抽出
   - エラーメッセージを定数化
   → テスト成功を維持 ✓

🎉 TDD Cycle 完了！
```

## Model Recommendation (REVIEW Phase)

| 項目 | 内容 |
|------|------|
| **デフォルトモデル** | Haiku |
| **代替候補** | Sonnet（複雑なビジネスロジックのテスト評価時） |
| **タスク複雑度** | 低〜中 |
| **必要コンテキスト** | テストファイル + 対応する実装ファイル |

### 根拠

- REVIEWフェーズはチェックリスト的評価であり、各ステップの判断基準が明確に定義されている
- テストファイルに限定されたコンテキストで動作するため、高度なコンテキスト理解は不要
- 5ステップの評価観点が構造化されており、機械的に判断可能な部分が多い
- Codex委任の最有力候補。評価基準が明確かつ定量的で、コンテキストが限定的

### 実行方式方針（必須手順）

**方針: Codex委任を原則とする（Issue #92 対応）**

#### Step 1: Codex CLI存在確認

**原則として、すべてのレビューはCodex CLIに委任すること。**

まず、Codex CLIの存在を確認します：

```bash
# Windows
where codex 2>nul && echo "Codex CLI available" || echo "Codex CLI not found"
```

- **Codex CLI が存在する場合** → Step 2（Codex委任）へ進む
- **Codex CLI が存在しない場合** → Step 3（Claude Codeフォールバック）へ進む

#### Step 2: Codex委任（原則）

`codex-delegate` スキルによるCodex CLI委任：
- レートリミット対策としてClaude Codeのトークン消費を削減
- Issue内容をコンテキストとして提供することでテストの意図を理解可能

#### Step 3: Claude Code（Codex CLI利用不可時のみ）

**Codex CLI利用不可時のみ**メインエージェント内で従来通り実行：

Codex CLI利用不可条件：
- Codex CLIがインストールされていない
- `OPENAI_API_KEY` が設定されていない
- Codex CLI実行がエラーで失敗した

## Tips

- **小さく始める**: 最初のテストは最もシンプルなケースから
- **1つずつ**: 一度に複数の機能を追加しない
- **頻繁に実行**: テストは数秒で実行できるようにする
- **失敗を歓迎**: REDフェーズでの失敗は正常な状態
- **1観点に集中**: REVIEWフェーズでは各ステップで1つの観点だけを評価（Progressive Pattern）
- **80点で前進**: 完璧を求めすぎず、80点以上で次へ進む
