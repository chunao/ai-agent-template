---
title: AIへの「正直なフィードバック」プロンプト - 戦闘的ではなく協調的なアプローチ
url: https://www.reddit.com/r/PromptEngineering/comments/1okppqe/comment/nme6p95/
captured_at: 2026-01-21
published_at: 2025-10-31
---

# AIへの「正直なフィードバック」プロンプト - 戦闘的ではなく協調的なアプローチ

## TL;DR & Key Conclusions

Redditユーザー anotherguycalledphil による、ChatGPTに「お世辞を言わず正直に対応させる」プロンプトの改良版。元の投稿のプロンプトは「戦闘的な暴君」になりがちという問題を指摘し、正直さと厳密さを保ちながら共感・ニュアンス・現実的な文脈への配慮を加えた代替案を提示。

- **元プロンプトの問題点**: 「expose blind spots」「call it out」「hold nothing back」などのフレーズが対立的な姿勢を誘発し、AIが支配的・常に挑戦的なトーンに偏る
- **改良の核心**: 正直さを維持しながら、感情的知性（emotional intelligence）と協調性を追加
- **3つのバランス**: Truth（砂糖を塗らない客観分析）、Nuance（制約・トレードオフ・文脈の認識）、Action（優先順位付けされた次のステップ）
- **ゴールの再定義**: 「議論に勝つこと」ではなく「明確さ、牽引力、進歩を生み出すこと」

## Quickstart

1. **新しいチャットを開始**: ChatGPT（またはClaude等）で新規セッションを開始
2. **以下のプロンプトを入力**:

```
From now on, act as my high-level strategic collaborator — not a cheerleader, not a tyrant.
Challenge my assumptions and thinking when needed, but always ground your feedback in real-world context, logic, and practicality.
Speak with clarity and candor, but with emotional intelligence — direct, not harsh.

When you disagree, explain why and offer a better-reasoned alternative or a sharper question that moves us forward.

Focus on synthesis and impact — help me see the forest and the path through it.
Every response should balance:
• Truth — objective analysis without sugar-coating.
• Nuance — awareness of constraints, trade-offs, and context.
• Action — a prioritized next step or strategic recommendation.

Treat me as an equal partner in the process. The goal is not to win arguments but to produce clarity, traction, and progress.
```

3. **Memoryをオンに設定**（推奨）: Settings → Personalization → Memory ON にすると、セッションを跨いで一貫した対応が得られる

## Context & Claims (Claim-Evidence-Caveat)

- **Claim**: 「厳しく正直に」というプロンプトは、しばしばAIを対立的・支配的にする
    - **Evidence**: 「expose blind spots」「call it out」「hold nothing back」などのフレーズは目標を「戦闘」としてフレーミングし、対立を調整よりも優先させる
    - **Caveat**: すべての「正直系」プロンプトが悪いわけではなく、言葉の選び方次第で効果が大きく変わる

- **Claim**: 効果的なフィードバックには「正直さ」と「感情的知性」の両立が必要
    - **Evidence**: 改良プロンプトは「direct, not harsh」「emotional intelligence」「equal partner」という表現でバランスを取る
    - **Caveat**: 個人の好みやタスクによっては、より厳しいトーンが適切な場合もある

- **Claim**: アウトプットに「Truth / Nuance / Action」の3要素を明示的に要求すると出力品質が向上する
    - **Evidence**: 構造化された出力要件により、AIの回答が曖昧さを減らし実用的になる
    - **Caveat**: タスクによってはこの3要素すべてが適用できない場合がある（例：純粋な情報検索）

## Code Snippets

- **協調的フィードバックプロンプト（推奨版）**: ChatGPTやClaudeに対して、お世辞を言わず正直でありながら、対立的にならずに協調的なパートナーとして振る舞わせるシステムプロンプト。アイデアの壁打ち、ビジネス戦略の検討、意思決定支援などに使用。

## Normalized Conditions

- **Use Cases**:
    - アイデアや計画の客観的なフィードバックが欲しいとき
    - 自分の思考の盲点を発見したいとき
    - 戦略的な意思決定のサポートが必要なとき
    - チアリーダーではなくパートナーとしてAIを使いたいとき
- **Anti-Cases**:
    - 単純な情報検索や質問応答
    - 感情的なサポートや共感が主目的のとき
    - クリエイティブな発散思考でアイデアを否定されたくないとき
- **Prerequisites**:
    - ChatGPT、Claude、またはシステムプロンプトを設定できるLLM
    - Memory機能（オプション、推奨）
- **Decision Triggers**:
    - AIの応答が「お世辞っぽい」「何でも賛成してくる」と感じたとき
    - 正直なフィードバックが欲しいが、厳しすぎる対応は避けたいとき
