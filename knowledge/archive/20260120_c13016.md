---
title: Claude Codeに別のAIエージェント（Codex等）を相談役として付けてみた
url: https://qiita.com/hiropon122/items/c130168ca3fc0f1f6aaa
captured_at: 2026-01-20
published_at: 2026-01-20
---

# Claude Codeに別のAIエージェント（Codex等）を相談役として付けてみた

## TL;DR & Key Conclusions
Claude Codeは優秀だが、完全放置するには不安が残るため、別のAIエージェント（Codex/Geminiなど）を「相談役」として付けるAgent Skillを開発・導入した事例。これにより、計画のレビューや実装後のチェックを自動化し、人間の監視コストを下げつつ信頼性を向上させた。

- **自律性の向上**: 外部エージェントによる「セカンドオピニオン」を取り入れることで、Claude単独よりも判断の精度が向上し、安心して任せられるようになった。
- **多様な視点**: 異なるモデル（Codex, Gemini）や役割（Peer/同僚役）を持つエージェントと相談させることで、多角的なフィードバックが得られる。
- **ワークフローの自動化**: `CLAUDE.md` に「開始時と終了時に必ずCodexにレビューさせる」ルールを記述することで、人間が介在せずに品質管理サイクルが回る。
- **過信の防止**: AI同士が共倒れ（誤った意見に同調）しないよう、「提案を鵜呑みにせず総合的に判断する」というルール付けが重要。

## Quickstart
1. **プラグインのインストール**:
   Marketsplaceからプラグインを追加し、必要なスキル（ask-codex, ask-gemini, ask-peer）をインストールする。
   ```bash
   claude plugin marketplace add hiroro-work/claude-plugins
   claude plugin install ask-codex@hiropon-plugins
   claude plugin install peer@hiropon-plugins
   ```

2. **使用方法**:
   会話中で「Codexにレビューして」と頼むか、スラッシュコマンドを使用する。
   ```
   /ask-codex
   /ask-peer
   ```

3. **自動化設定**:
   `CLAUDE.md` に相談ルールを記述し、作業の節目で自動的にレビューが行われるようにする。

## Context & Claims (Claim-Evidence-Caveat)
- **Claim**: 単一のエージェント（Claude）だけでは、完全な自律作業を任せるには不安がある。
    - **Evidence**: ユーザーは「計画段階でのレビュー」「軌道修正」「完了時のチェック」のために、頻繁に様子を見に行く必要があった（「横についていないと不安」）。
    - **Caveat**: AIエージェント自体は優秀だが、独断で誤った方向に進むリスクがゼロではない。

- **Claim**: マルチエージェント（相談役）システムは、手戻りを減らし、見落としを防ぐ。
    - **Evidence**: 実装前にCodexが計画をレビューし、不足点を指摘する例（「OAuth失敗時のフォールバックは？」等）。筆者の体験として「実装後の手戻りが減った」「自分では気づかない考慮漏れを指摘してくれる」との報告。

- **Claim**: 第三者製プラグインにはセキュリティリスクがある。
    - **Evidence**: 悪意のあるコードが含まれる可能性があるため、コード確認や信頼できるソースの利用が推奨される。

## Normalized Conditions
- **Use Cases**:
    - 長時間の自律タスク実行（人間が離席したい場合）
    - 厳密な仕様管理や高い信頼性が求められる複雑な機能実装
    - 異なるモデルの視点（セカンドオピニオン）を取り入れたい場合
- **Anti-Cases**:
    - 単純な修正や、スピード最優先のプロトタイピング（相談のオーバーヘッドが無駄になる）
    - 外部CLIツールやプラグインの導入が制限されている環境
- **Prerequisites**:
    - Claude Code環境
    - 外部エージェントを使用する場合は対応するCLI（Codex, Gemini等）
- **Decision Triggers**:
    - AIの自律実行を監視する手間（張り付き）を削減したいと感じた時
    - AIの出力に論理的ミスや考慮漏れが目立つ時
- **Failure Modes / Risks**:
    - **盲信リスク**: Claudeが相談役の意見を無批判に受け入れ、正しい判断を曲げてしまう（対策：ルールで「鵜呑みにしない」と明記）。
    - **無限ループ**: 議論がまとまらず、相談が長引く可能性（通常はモデルの最大ターン数などで止まるが注意）。
    - **セキュリティ**: 悪意あるプラグインによる情報漏洩やシステム破壊。
- **Operational Cost**:
    - 相談役エージェントのAPI利用料/トークンコスト
    - 相談プロセスによるタスク完了までの時間増加
